CONFIGURATIONS = [
    # TM, TN, TK, BX, BY
    (16, 16, 16, 16, 16),
    (32, 32, 32, 32, 8),
    (64, 32, 16, 32, 16),
    (32, 64, 16, 64, 8),
    (128, 16, 8, 16, 32),
]


def generate_header():
    header_content = """
#pragma once
#include "KernelConfig.h"
#include "kernel.cuh"
#include <iostream>

// THIS FILE IS AUTO-GENERATED BY generate_dispatcher.py
// DO NOT EDIT MANUALLY

void launch_kernel_with_config(const KernelConfig &config, float *d_C,
                               const float *d_A, const float *d_B, int M, int N,
                               int K) {
    dim3 blockDim(config.BLOCK_DIM_X, config.BLOCK_DIM_Y);
    dim3 gridDim((N + config.TILE_N - 1) / config.TILE_N,
                 (M + config.TILE_M - 1) / config.TILE_M);
    size_t shared_size = (static_cast<size_t>(config.TILE_M) * config.TILE_K +
                          static_cast<size_t>(config.TILE_K) * config.TILE_N) *
                         sizeof(float);
"""

    first = True
    for tm, tn, tk, bx, by in CONFIGURATIONS:
        condition = f"config.TILE_M == {tm} && config.TILE_N == {tn} && config.TILE_K == {tk} && config.BLOCK_DIM_X == {bx} && config.BLOCK_DIM_Y == {by}"
        launch = f"matrix_multiply_kernel<{tm}, {tn}, {tk}, {bx}, {by}><<<gridDim, blockDim, shared_size>>>(d_C, d_A, d_B, M, N, K);"

        if first:
            header_content += f"    if ({condition}) {{\n        {launch}\n    }}"
            first = False
        else:
            header_content += f" else if ({condition}) {{\n        {launch}\n    }}"

    header_content += """
    else {
        std::cerr << "FATAL: Unsupported kernel configuration: " << config.toString() << std::endl;
        exit(1);
    }
    CUDA_CHECK(cudaGetLastError());
}
"""
    with open("Evaluator_dispatcher.h", "w") as f:
        f.write(header_content)


if __name__ == "__main__":
    generate_header()
    print("Generated Evaluator_dispatcher.h successfully.")
